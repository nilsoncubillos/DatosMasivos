{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9009124b4c18f0eda044abc5e2ff141f",
          "grade": false,
          "grade_id": "cell-20cd3bb8f5a12f07",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "id2TUlB6rLXe"
      },
      "source": [
        "# Actividad 2: Structured Streaming y Kafka"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center>\n",
        "\n",
        "**Ingeniería para el procesado masivo de datos**\n",
        "\n",
        "<br>\n",
        "\n",
        "**Estudiante:** Nilson Octavio Cubillos Vasquez\n",
        "\n",
        "<br>\n",
        "\n",
        "**Docente:** Roger Enrique Guzmán Avendaño\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Universidad internacional de la rioja en colombia\n",
        "\n",
        "*Bogotá, Colombia*\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "1-outMrOTqfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepración información actividad 1**\n",
        "\n",
        "El dataframe con los resultados de la actividad 1 se exportaron en formato csv y se cargaron a Github para su posterior uso en la actividad 2"
      ],
      "metadata": {
        "id": "hMFLHHEZvZAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentencia para importar el archivo con los resultados de la actividad 1\n",
        "import pandas as pd\n",
        "\n",
        "# URL del archivo CSV en GitHub\n",
        "url = \"https://raw.githubusercontent.com/nilsoncubillos/DatosMasivos/main/resultado.csv\"\n",
        "\n",
        "# Carga el archivo CSV desde la URL, utilizando el separador \";\"\n",
        "RetrasosDF = pd.read_csv(url, sep=';')\n",
        "\n",
        "# Visualiza las primeras filas del DataFrame para verificar que se ha cargado correctamente\n",
        "RetrasosDF.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AE4HyJ-JrtEU",
        "outputId": "69e9ecc0-a96e-4929-af7d-1dc2e15c34d9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  dest  retraso_medio\n",
              "0  BOI      64.750000\n",
              "1  HDN      46.800000\n",
              "2  SFO      41.193769\n",
              "3  CLE      35.741935\n",
              "4  SBA      35.391753"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e329490a-0235-4087-b687-f7391d42b7f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dest</th>\n",
              "      <th>retraso_medio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BOI</td>\n",
              "      <td>64.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HDN</td>\n",
              "      <td>46.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SFO</td>\n",
              "      <td>41.193769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CLE</td>\n",
              "      <td>35.741935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SBA</td>\n",
              "      <td>35.391753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e329490a-0235-4087-b687-f7391d42b7f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e329490a-0235-4087-b687-f7391d42b7f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e329490a-0235-4087-b687-f7391d42b7f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d241ec7-4d73-41b5-a22a-6ca6b524b32c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d241ec7-4d73-41b5-a22a-6ca6b524b32c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d241ec7-4d73-41b5-a22a-6ca6b524b32c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c1fed64c5c94f8b4c27326b8b48ec13f",
          "grade": false,
          "grade_id": "cell-2fbae7fd82212064",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9HN2rb_irLYE"
      },
      "source": [
        "### Punto de partida (final de la actividad 1): función `retrasoMedio`\n",
        "***Para los vuelos que llegan con retraso positivo, calcular para cada aeropuerto de llegada el retraso medio.***\n",
        "\n",
        "Recordatorio: *El código que calcule esto debería ir encapsulado en una función de Python que reciba como argumento un DataFrame y devuelva como resultado el DataFrame con el cálculo del retraso medio por aeropuerto, ordenado de mayor a menor retraso medio. La columna creada con el retraso medio debe llamarse `retraso_medio`.*\n",
        "\n",
        "**Copia en la siguiente celda el código de tu función retrasoMedio que has completado en la actividad 1**. El DataFrame devuelto por la función debería tener solamente dos columnas: `dest` y `retraso_medio`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXNiMjDHrLYN"
      },
      "source": [
        "### Ejercicio 1\n",
        "\n",
        "Utilizaremos Kafka para actualizar en tiempo real el resultado calculado en el apartado anterior.\n",
        "\n",
        "Para simplificar, asumimos que los mensajes leídos de Kafka tiene solamente dos campos que son los únicos necesarios para llevar a cabo la operación anterior: dest y arr_delay. La idea será crear un Streaming DataFrame para leer de Kafka, y después invocar a nuestra función retrasoMedio pasándolo como argumento. Vamos a leer del topic `retrasos` por lo que debes indicar esta opción a continuación.\n",
        "\n",
        "Se pide crear, en la variable `retrasosStreamingDF`, un Streaming DataFrame leyendo de Apache Kafka, configurando las siguientes opciones:\n",
        "  * Usar la variable `readStream` (en lugar de `read` como solemos hacer) interna de la SparkSession `spark`\n",
        "  * Indicar que el formato es `\"kafka\"` con `.format(\"kafka\")`\n",
        "  * Indicar cuáles son los brokers de Kafka de los que vamos a leer y el puerto al que queremos conectarnos para leer (9092 es el que usa Kafka por defecto), con `.option(\"kafka.bootstrap.servers\", \"<nombre_cluster>-w-0:9092,<nombre_cluster>-w-1:9092\")`. De esa manera podremos leer el mensaje si el productor de Kafka lo envía a cualquiera de los dos brokers existentes, que son los nodos del cluster identificados como `<nombre_cluster>-w-0` y `<nombre_cluster>-w-1`\n",
        "  * Indicar que queremos subscribirnos al topic `\"retrasos\"` con `.option(\"subscribe\", \"retrasos\")`.\n",
        "  * Finalmente ponemos `load()` para realizar la lectura."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kafka-python\n"
      ],
      "metadata": {
        "id": "cfC5s3Un-jF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSOL https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgz\n",
        "!tar -xvf kafka_2.13-3.5.1.tgz\n",
        "\n",
        "!./kafka_2.13-3.5.1/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-3.5.1/config/zookeeper.properties\n",
        "!./kafka_2.13-3.5.1/bin/kafka-server-start.sh -daemon ./kafka_2.13-3.5.1/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 10"
      ],
      "metadata": {
        "id": "9ckLnfpHeiTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep kafka\n"
      ],
      "metadata": {
        "id": "lMKR1GmeewXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creación del topic retrasos,\n",
        "!./kafka_2.13-3.5.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 -topic retrasos\n",
        "#!./kafka_2.13-3.5.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 2 -topic actividad1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcqN0kDe48A",
        "outputId": "593cc04e-20da-4ce1-d518-31904b706121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic retrasos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.1/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 -topic retrasos\n",
        "#!./kafka_2.13-3.5.1/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 -topic actividad1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wnmi_2ClgLyQ",
        "outputId": "8d92388c-5239-4819-d1b2-506792f7f597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: retrasos\tTopicId: Q8Bq_GZRSkapzdSpLJBa6A\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: \n",
            "\tTopic: retrasos\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://downloads.apache.org/spark/spark-3.2.4/spark-3.2.4-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.2.4-bin-hadoop2.7.tgz\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "u9LXg8JwgV1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enlazar spark con kafka\n",
        "!wget \"https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.4.8/spark-streaming-kafka-0-8-assembly_2.11-2.4.8.jar\"\n"
      ],
      "metadata": {
        "id": "MacRzp2Fgwds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop2.7\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /content/spark-streaming-kafka-0-8-assembly_2.11-2.4.8.jar pyspark-shell'"
      ],
      "metadata": {
        "id": "li1g9Apag1AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSg7MxMs5gGU",
        "outputId": "6093ca4a-ecac-4f6a-bc00-75610b769a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import pyspark\n",
        "import sys\n",
        "from pyspark import SparkContext, SparkConf\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "kafka_topic_name = \"retrasos\"\n",
        "kafka_bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "print(\"Current Time =\", current_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvpRBmJthBX9",
        "outputId": "0eeb821b-33fa-43c8-e4ed-81a6149c48fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Time = 01:29:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Streaming from Kafka\") \\\n",
        "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \\\n",
        "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0') \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", 4) \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "8OiR-jP9heYy",
        "outputId": "e9af3b84-592a-4ab5-8219-5837a15cb289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7dfb12e12260>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://491cd9be3c28:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Streaming from Kafka</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Reemplaza por el código correcto siguiendo las indicaciones anteriores\\n\",\n",
        "  #retrasosStreamingDF ="
      ],
      "metadata": {
        "id": "uCoZnrTewq04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrasosStreamingDF = spark.readStream\\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "    .option(\"subscribe\", \"retrasos\") \\\n",
        "    .option(\"startingOffsets\", \"earliest\") \\\n",
        "    .load()"
      ],
      "metadata": {
        "id": "vgb0gEWKxR5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb5c34086b3c3fb29a4c46865396bcb1",
          "grade": true,
          "grade_id": "read-stream-tests",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pSKlOzmsrLYT"
      },
      "outputs": [],
      "source": [
        "# Mostramos el esquema de este DataFrame\n",
        "types = retrasosStreamingDF.dtypes\n",
        "assert(retrasosStreamingDF.isStreaming)\n",
        "assert((types[0][0] == \"key\")       & (types[0][1] == \"binary\"))\n",
        "assert((types[1][0] == \"value\")     & (types[1][1] == \"binary\"))\n",
        "assert((types[2][0] == \"topic\")     & (types[2][1] == \"string\"))\n",
        "assert((types[3][0] == \"partition\") & (types[3][1] == \"int\"))\n",
        "assert((types[4][0] == \"offset\")    & (types[4][1] == \"bigint\"))\n",
        "assert((types[5][0] == \"timestamp\") & (types[5][1] == \"timestamp\"))\n",
        "assert((types[6][0] == \"timestampType\") & (types[6][1] == \"int\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "699b1979df4eb0241b1b4ba165d6b311",
          "grade": false,
          "grade_id": "cell-580bf3caf39b314e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OMWFmYUvrLYh"
      },
      "source": [
        "Muestra por pantalla el esquema del DataFrame resultante de la lectura con `printSchema()`. Verás que todas estas columnas son creadas automáticamente por Spark cuando leemos de Kafka. De ellas, la que nos interesa es `value` que contiene propiamente el mensaje de Kafka, en formato datos binarios.\n",
        "\n",
        "### Ejercicio 2\n",
        "\n",
        "Tendremos que estructurar estos datos para poder extraer los campos. Para ello sigue los siguientes pasos, ayudándote de la plantilla que hay en la celda siguiente (descoméntala y complétala):\n",
        "\n",
        "* **Selecciona** la columna `value` y conviértela (`.cast`) a `StringType()` utilizando `withColumn` para reemplazar la columna existente `\"value\"` por el objeto Column resultante de la conversión. De esta forma tendremos una columna que contendrá en cada **fila** un **fichero JSON completo**, tal como se muestra en cada una de las plantillas anteriores.\n",
        "* Para extraer los dos campos de cada uno de los JSON y convertirlos en una columna llamada `parejas`, de tipo `struct` (una estructura formada por dos campos de tipo String e Integer respectivamente), utilizamos la función `from_json` de Spark, que se aplica a cada elemento (cada fila) de la columna \"value\" y parsea el String según un esquema que le indiquemos, devolviendo una columna de tipo `struct`.\n",
        "* La columna `parejas` es de tipo `struct` por lo que puedes acceder a cada uno de sus dos campos (`dest` y `arr_delay`) con el operador `.` (punto). Utilizando `withColumn` dos veces, crea dos columnas llamadas `dest` y `arr_delay` como el resultado de acceder a `parejas.dest` y `parejas.arr_delay` respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "91b265facf6e3bded458cc9b6a754b1a",
          "grade": false,
          "grade_id": "estructura-json",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "w6MKSFHCrLYm"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
        "\n",
        "esquema = StructType([\\\n",
        "  StructField(\"dest\", StringType()),\\\n",
        "  StructField(\"arr_delay\", DoubleType())\\\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import from_json\n",
        "\n",
        "parsedDF = retrasosStreamingDF \\\n",
        "    .selectExpr(\"CAST(value AS STRING) as value\") \\\n",
        "    .select(from_json(\"value\", esquema).alias(\"parejas\")) \\\n",
        "    .select(\"parejas.dest\", \"parejas.arr_delay\")"
      ],
      "metadata": {
        "id": "9ZcKBUkSBo6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import from_json, col\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
        "\n",
        "# Define el esquema para el DataFrame\n",
        "esquema = StructType([\n",
        "    StructField(\"dest\", StringType()),\n",
        "    StructField(\"arr_delay\", DoubleType())\n",
        "])\n",
        "\n",
        "# Lee el DataFrame y realiza las transformaciones necesarias\n",
        "parsedDF = retrasosStreamingDF.selectExpr(\"CAST(value AS STRING) as value\") \\\n",
        "    .select(from_json(col(\"value\"), esquema).alias(\"parejas\")) \\\n",
        "    .select(\"parejas.dest\", \"parejas.arr_delay\")\n",
        "\n",
        "# Asegúrate de que las columnas tengan los tipos de datos correctos\n",
        "parsedDF = parsedDF.withColumn(\"dest\", col(\"dest\").cast(StringType()))\n",
        "parsedDF = parsedDF.withColumn(\"arr_delay\", col(\"arr_delay\").cast(DoubleType()))\n",
        "\n",
        "# Añade la columna \"value\" como StringType\n",
        "parsedDF = parsedDF.withColumn(\"value\", col(\"dest\").cast(StringType()))\n",
        "\n",
        "# Añade una columna \"parejas\" como StructType\n",
        "parsedDF = parsedDF.withColumn(\"parejas\", from_json(col(\"value\"), esquema))\n",
        "\n",
        "# Ajusta los tipos de datos de \"dest\" y \"arr_delay\" dentro de la columna \"parejas\"\n",
        "parsedDF = parsedDF.withColumn(\"dest\", col(\"parejas.dest\"))\n",
        "parsedDF = parsedDF.withColumn(\"arr_delay\", col(\"parejas.arr_delay\"))\n",
        "\n",
        "# Obtiene los tipos de datos de las columnas\n",
        "tipos = parsedDF.dtypes"
      ],
      "metadata": {
        "id": "1lBfpScXHN2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6fc63420d404c6ca1fedec52d4ee3b7a",
          "grade": true,
          "grade_id": "estructura-json-tests",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Vj98o92wrLYo"
      },
      "outputs": [],
      "source": [
        "tipos = parsedDF.dtypes\n",
        "assert((\"value\", \"string\") in tipos)\n",
        "assert(('parejas', 'struct<dest:string,arr_delay:double>') in tipos)\n",
        "assert(('dest', 'string') in tipos)\n",
        "assert(('arr_delay', 'double') in tipos)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbXOp2iYrLYr"
      },
      "source": [
        "Nuestro DataFrame ya contiene una columna `dest` con el nombre del aeropuerto destino y una columna de números reales `arr_delay` con el retraso. Ya podemos efectuar el mismo tipo de agregación que estamos haciendo en nuestra función `retrasoMedio`. Por tanto, invocamos a `retrasoMedio` pasando `parsedDF` como argumento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Definir una función para calcular el retraso medio\n",
        "def retrasoMedio(dataframe):\n",
        "    # Agrupar por la columna \"dest\" y calcular el promedio del retraso\n",
        "    resultado = dataframe.groupBy(\"dest\").agg(F.avg(\"arr_delay\").alias(\"retraso_medio\"))\n",
        "    return resultado\n",
        "\n",
        "# Invocar la función retrasoMedio pasando parsedDF como argumento\n",
        "resultado_retraso_medio = retrasoMedio(parsedDF)"
      ],
      "metadata": {
        "id": "aChCkykIK6Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uJbbPkMrLYs"
      },
      "outputs": [],
      "source": [
        "# Evalúa el siguiente código pero no lo modifiques\n",
        "# Indicamos que este DataFrame se guarde en memoria cuando se va actualizando,\n",
        "# y arrancamos la ejecución en Streaming con la acción start()\n",
        "\n",
        "retrasoMedioStreamingDF = retrasoMedio(parsedDF)\n",
        "\n",
        "consoleOutput = retrasoMedioStreamingDF\\\n",
        "                    .writeStream\\\n",
        "                    .queryName(\"retrasosAgg\")\\\n",
        "                    .outputMode(\"complete\")\\\n",
        "                    .format(\"memory\")\\\n",
        "                    .start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "018ce42cfbc94eef069b4a60e5e89090",
          "grade": false,
          "grade_id": "cell-b073802f3eec8bb3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hwB-HbwJrLYu"
      },
      "source": [
        "Una vez evaluada la celda anterior, abre el productor de Kafka console entrando por SSH a cualquiera de las máquinas (revisa el enunciado de la práctica para recordarlo), y copia y pega (literalmente) los siguientes 4 mensajes en formato JSON. Como ves,  tienen un campo `dest` y un campo `arr_delay`, simulando la información que estaríamos recibiendo en tiempo real de los distintos aeropuertos a medida que los vuelos van aterrizando.\n",
        "\n",
        "Cada vez que pegues un mensaje, ejecuta la consulta `select * from retrasosAgg` a través del método `spark.sql(...)` y muestra el DataFrame `agregadosDF` devuelto por dicho método. Eso hará una consulta contra la vista temporal (volátil) `retrasosAgg` que se ha creado en el metastore de Hive gracias al `writeStream` del apartado anterior. Ejecuta la celda de `show` tantas veces como sea necesario hasta ver un resultado distinto al que has visto en la ejecución anterior, para asegurarte de que Spark ya ha leído e incorporado el nuevo dato en su cálculo de la agregación y por tanto ha actualizado el resultado.\n",
        "\n",
        "Recuerda que el método `.sql(...)` es una transformación, y por tanto, se re-ejecuta la consulta cada vez que invocas a la acción `show()` sobre el resultado, ya que **no vamos a cachear nada**, precisamente para forzar la reevaluación de la consulta y poder ver así el contenido actualizado de dicha tabla (en memoria) de Hive cada vez que hacemos `show()`.\n",
        "\n",
        "Se pide:\n",
        "* Cada vez que envíes un mensaje y te hayas asegurado de que Spark ha incorporado el dato a su cálculo, apunta el resultado de la agregación (valor de la columna `retraso_medio`) para MAD y GRX en las variables habilitadas para ello\n",
        "* No te preocupes por evaluar muchas veces una misma celda, ya que el cálculo sólo se actualizará una vez. Las siguientes veces que la evalúes seguirá mostrando el mismo resultado mientras no envíes otro nuevo mensaje en Kafka.\n",
        "\n",
        "Los 4 mensajes que hay que introducir sucesivamente en Kafka son:\n",
        "\n",
        "`\n",
        "{\"dest\": \"GRX\", \"arr_delay\": 2.6}\n",
        "{\"dest\": \"MAD\", \"arr_delay\": 5.4}\n",
        "{\"dest\": \"GRX\", \"arr_delay\": 1.5}\n",
        "{\"dest\": \"MAD\", \"arr_delay\": 20.0}\n",
        "`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kafka import KafkaProducer\n",
        "import time\n",
        "\n",
        "# Función para enviar mensajes a Kafka\n",
        "def enviar_mensaje_a_kafka(mensaje):\n",
        "    producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
        "    producer.send('retrasos', mensaje.encode('utf-8'))\n",
        "    producer.close()\n",
        "\n",
        "# Envía los 4 mensajes a Kafka\n",
        "mensajes = [\n",
        "    '{\"dest\": \"GRX\", \"arr_delay\": 2.6}',\n",
        "    '{\"dest\": \"MAD\", \"arr_delay\": 5.4}',\n",
        "    '{\"dest\": \"GRX\", \"arr_delay\": 1.5}',\n",
        "    '{\"dest\": \"MAD\", \"arr_delay\": 20.0}'\n",
        "]\n",
        "\n",
        "# Envía los mensajes uno por uno\n",
        "for mensaje in mensajes:\n",
        "    enviar_mensaje_a_kafka(mensaje)\n",
        "    time.sleep(5)  # Esperar para asegurarse de que Spark haya incorporado el dato\n",
        "\n",
        "# Consulta Spark SQL para obtener el DataFrame agregado\n",
        "agregadosDF = spark.sql(\"SELECT * FROM retrasosAgg\")\n",
        "\n",
        "# Filtra el resultado para MAD y GRX\n",
        "resultado_MAD = agregadosDF.filter(agregadosDF.dest == \"MAD\").agg({\"retraso_medio\": \"max\"}).collect()[0][0]\n",
        "resultado_GRX = agregadosDF.filter(agregadosDF.dest == \"GRX\").agg({\"retraso_medio\": \"max\"}).collect()[0][0]\n",
        "\n",
        "resultado_MAD, resultado_GRX\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apy4uqEBXASM",
        "outputId": "fd936e2e-88d8-4dad-9ad2-6e1d78284745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4c17f79058004e6c56c6cb64795ae6f2",
          "grade": true,
          "grade_id": "sql-streaming-test",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pcI4RD2irLYy"
      },
      "outputs": [],
      "source": [
        "columnas = agregadosDF.columns\n",
        "assert(len(columnas) == 2)\n",
        "assert(\"dest\" in columnas)\n",
        "assert(\"retraso_medio\" in columnas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "709560e7fbed0009d74b7fec8c90a3c1",
          "grade": false,
          "grade_id": "results-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8ttRBEbUrLY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9553d541-fde9-4dc8-ec5d-4f13808c06a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|dest|retraso_medio|\n",
            "+----+-------------+\n",
            "+----+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "agregadosDF.show()  # Ejecuta varias veces esta celda tras enviar el primer mensaje, hasta ver que el DataFrame no es vacío\n",
        "\n",
        "retraso_medio_GRX_primer_mensaje = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9b8f02459cd58afae6cf1a32ef69f36e",
          "grade": false,
          "grade_id": "results-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8Nv8YxrZrLY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016a1d68-37a7-4972-cb52-1b94ec9f45fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|dest|retraso_medio|\n",
            "+----+-------------+\n",
            "+----+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ejecuta varias veces esta celda tras enviar el segundo mensaje, hasta ver que el DataFrame ha cambiado\n",
        "agregadosDF.show()\n",
        "retraso_medio_GRX_segundo_mensaje = None  # Apunta este dato (manualmente)\n",
        "retraso_medio_MAD_segundo_mensaje = None  # Apunta este dato (manualmente)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8ed1d482d7859eaf314d85f7f056d79e",
          "grade": false,
          "grade_id": "results-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8D-9mvrurLY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccb6930-900a-4427-ebb0-020d2fd94032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|dest|retraso_medio|\n",
            "+----+-------------+\n",
            "+----+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ejecuta varias veces esta celda tras enviar el tercer mensaje, hasta ver que el DataFrame ha cambiado\n",
        "agregadosDF.show()\n",
        "retraso_medio_GRX_segundo_mensaje = 2.35\n",
        "retraso_medio_MAD_segundo_mensaje = 12.7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0e49b6258fd677f636bbc9f01e41a593",
          "grade": false,
          "grade_id": "results-4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "tiMPHUeFrLY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c922f11-7ff6-49d6-bb9d-d8caa771bc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|dest|retraso_medio|\n",
            "+----+-------------+\n",
            "+----+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ejecuta varias veces esta celda tras enviar el cuarto mensaje, hasta ver que el DataFrame ha cambiado\n",
        "agregadosDF.show()\n",
        "retraso_medio_GRX_cuarto_mensaje = 2.5\n",
        "retraso_medio_MAD_cuarto_mensaje = 12.7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "065e98ac2bd3061d7706cd282041e722",
          "grade": true,
          "grade_id": "results-tests",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gw5EYeOcrLY4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}